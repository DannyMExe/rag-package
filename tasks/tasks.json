{
  "tasks": [
    {
      "id": 1,
      "title": "Setup Project Repository",
      "description": "Initialize a new Git repository for the LawFirm-RAG project.",
      "details": "Create a new directory for the project and initialize a Git repository using `git init`. Set up a `.gitignore` file to exclude unnecessary files like `__pycache__`, `.env`, and others.",
      "testStrategy": "Verify that the repository is initialized correctly and that the `.gitignore` file is functioning as expected.",
      "priority": "high",
      "dependencies": [],
      "status": "done",
      "subtasks": []
    },
    {
      "id": 2,
      "title": "Restructure Codebase",
      "description": "Reorganize the existing codebase into a standard Python package layout.",
      "details": "Move existing code files into the new structure as outlined in the PRD. Create directories for `cli`, `core`, `api`, `models`, `utils`, and `web`. Ensure all modules are properly imported in the new structure.",
      "testStrategy": "Run existing unit tests to ensure that the codebase functions correctly after restructuring.",
      "priority": "high",
      "dependencies": [
        1
      ],
      "status": "done",
      "subtasks": []
    },
    {
      "id": 3,
      "title": "Create pyproject.toml",
      "description": "Set up the `pyproject.toml` file for modern Python packaging.",
      "details": "Create a `pyproject.toml` file that includes metadata such as package name, version, author, and dependencies. Follow PEP 518 and PEP 621 standards.",
      "testStrategy": "Validate the `pyproject.toml` file using `poetry check` or similar tools to ensure it meets packaging standards.",
      "priority": "high",
      "dependencies": [
        2
      ],
      "status": "done",
      "subtasks": []
    },
    {
      "id": 4,
      "title": "Implement setup.py for Backward Compatibility",
      "description": "Create a `setup.py` file for backward compatibility with older pip versions.",
      "details": "Write a `setup.py` script that reads from `pyproject.toml` and specifies package metadata and dependencies for older pip versions.",
      "testStrategy": "Test installation using `pip install .` to ensure compatibility with older pip versions.",
      "priority": "medium",
      "dependencies": [
        3
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 5,
      "title": "Define Dependencies in requirements.txt",
      "description": "Create a `requirements.txt` file for development and production dependencies.",
      "details": "List all necessary dependencies in `requirements.txt`, including version constraints to avoid conflicts. Include separate sections for development and production dependencies.",
      "testStrategy": "Run `pip install -r requirements.txt` to verify that all dependencies are installed correctly.",
      "priority": "medium",
      "dependencies": [
        3
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 6,
      "title": "Implement CLI Entry Points",
      "description": "Set up command-line interface entry points for the package. The CLI framework has been successfully completed with comprehensive features and modules.",
      "status": "done",
      "dependencies": [
        3
      ],
      "priority": "high",
      "details": "Define entry points in `pyproject.toml` for the CLI commands such as `lawfirm-rag analyze`, `lawfirm-rag query`, `lawfirm-rag serve`, `lawfirm-rag models`, and `lawfirm-rag config`. Implement the main command logic in `lawfirm_rag/cli/main.py` using the Click framework. The CLI now supports rich console output, multiple output formats, and batch processing.",
      "testStrategy": "Run `lawfirm-rag --help` to ensure that the CLI commands are accessible and display the correct help information. Verify that each command functions as intended, including document analysis, query generation, web server operation, and model management.",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Main CLI Entry Point",
          "status": "done",
          "description": "Create the main CLI entry point in `lawfirm_rag/cli/main.py` using the Click framework."
        },
        {
          "id": 2,
          "title": "Configure Entry Points in pyproject.toml",
          "status": "done",
          "description": "Set up entry points in `pyproject.toml` for both `lawfirm-rag` and `lrag` commands."
        },
        {
          "id": 3,
          "title": "Implement CLI Commands",
          "status": "done",
          "description": "Develop the following CLI commands: `lawfirm-rag analyze`, `lawfirm-rag query`, `lawfirm-rag serve`, `lawfirm-rag models`, and `lawfirm-rag config`."
        },
        {
          "id": 4,
          "title": "Create Supporting Modules",
          "status": "done",
          "description": "Implement supporting modules for CLI functionality, including document analysis, query generation, web server startup, configuration management, and model management."
        },
        {
          "id": 5,
          "title": "Test CLI Functionality",
          "status": "done",
          "description": "Run tests to ensure all CLI commands work as expected and handle errors gracefully."
        },
        {
          "id": 6,
          "title": "Verify Package Installation",
          "status": "done",
          "description": "Ensure the package installs successfully with `pip install -e .` and that all dependencies are resolved correctly."
        },
        {
          "id": 7,
          "title": "Add Additional Testing for New Features",
          "status": "done",
          "description": "Create tests for new features such as batch processing support, API authentication, and fallback analysis."
        }
      ]
    },
    {
      "id": 7,
      "title": "Develop Document Processing Module",
      "description": "The document processing module has been fully implemented and integrated, providing comprehensive functionality for processing various document formats.",
      "status": "done",
      "dependencies": [
        2
      ],
      "priority": "high",
      "details": "The module is located in `core/document_processor.py` and supports PDF, DOCX, and TXT file processing. It includes session-based document management for web API integration, robust error handling, and logging. The module is now production-ready and fully integrated with both CLI and API interfaces.",
      "testStrategy": "Verify that the document processing functions work as expected through unit tests. Ensure that the CLI and API integrations function correctly and handle various file types and edge cases.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create core/document_processor.py",
          "status": "done",
          "description": "Created comprehensive `core/document_processor.py` with full functionality."
        },
        {
          "id": 2,
          "title": "Implement multi-format support",
          "status": "done",
          "description": "Supports PDF, DOCX, and TXT file processing."
        },
        {
          "id": 3,
          "title": "Implement session management",
          "status": "done",
          "description": "Create sessions for batch document processing."
        },
        {
          "id": 4,
          "title": "Implement text extraction",
          "status": "done",
          "description": "Efficient text extraction with proper encoding handling."
        },
        {
          "id": 5,
          "title": "Implement file management",
          "status": "done",
          "description": "Temporary file handling with automatic cleanup."
        },
        {
          "id": 6,
          "title": "Implement error handling",
          "status": "done",
          "description": "Graceful handling of corrupted files and missing dependencies."
        },
        {
          "id": 7,
          "title": "Implement memory efficiency",
          "status": "done",
          "description": "Processes large documents without memory issues."
        },
        {
          "id": 8,
          "title": "Integrate with CLI",
          "status": "done",
          "description": "Works seamlessly with `lawfirm-rag analyze` command."
        },
        {
          "id": 9,
          "title": "Integrate with API",
          "status": "done",
          "description": "Integrated with FastAPI endpoints for web interface."
        },
        {
          "id": 10,
          "title": "Implement configuration management",
          "status": "done",
          "description": "Uses ConfigManager for customizable settings."
        },
        {
          "id": 11,
          "title": "Implement logging",
          "status": "done",
          "description": "Comprehensive logging for debugging and monitoring."
        },
        {
          "id": 12,
          "title": "Implement cleanup session",
          "status": "done",
          "description": "Cleans up temporary files and session data."
        },
        {
          "id": 13,
          "title": "Verify testing",
          "status": "done",
          "description": "Testing verified for package imports, CLI integration, and API functionality."
        },
        {
          "id": 14,
          "title": "Update documentation",
          "status": "done",
          "description": "Update the documentation to reflect the new features and usage of the document processing module."
        }
      ]
    },
    {
      "id": 8,
      "title": "Integrate AI Engine",
      "description": "Integrate the AI engine for model loading and inference, now fully implemented and integrated with advanced features for legal document analysis.",
      "status": "done",
      "dependencies": [
        7
      ],
      "priority": "high",
      "details": "The AI engine logic has been successfully implemented in `core/ai_engine.py`, featuring full GGUF model support and utilizing `llama-cpp-python` for improved local inference performance. It supports legal-specific document analysis and query generation, with robust error handling and fallback mechanisms.",
      "testStrategy": "Test the AI engine with various legal documents to ensure it produces expected results across all implemented features, including document summarization, key points extraction, and legal issues identification.",
      "subtasks": [
        {
          "id": 1,
          "title": "Create core AI engine implementation",
          "status": "completed",
          "description": "Developed comprehensive `core/ai_engine.py` with full GGUF model support."
        },
        {
          "id": 2,
          "title": "Integrate llama-cpp-python for inference",
          "status": "completed",
          "description": "Replaced transformers with `llama-cpp-python` for better local inference performance."
        },
        {
          "id": 3,
          "title": "Implement legal-specific document analysis",
          "status": "completed",
          "description": "Added support for legal-specific prompts and multiple analysis types."
        },
        {
          "id": 4,
          "title": "Implement error handling and fallback mechanisms",
          "status": "completed",
          "description": "Ensured robust error handling and fallback support for model loading failures."
        },
        {
          "id": 5,
          "title": "Verify AI engine testing",
          "status": "completed",
          "description": "Confirmed that the AI engine package imports successfully and all analysis methods work with fallback support."
        },
        {
          "id": 6,
          "title": "Add performance optimizations",
          "status": "completed",
          "description": "Optimized for local processing and efficient memory usage."
        },
        {
          "id": 7,
          "title": "Conduct comprehensive testing",
          "status": "done",
          "description": "Test the AI engine with various legal documents to ensure all features work as expected."
        }
      ]
    },
    {
      "id": 9,
      "title": "Implement SQLite Storage Layer",
      "description": "Create a SQLite-based storage layer for document management.",
      "details": "Implement the storage logic in `core/storage.py` using SQLite for data persistence. Use `sqlite3` for database interactions and ensure proper migrations are handled.",
      "testStrategy": "Run integration tests to verify that documents can be stored and retrieved correctly from the SQLite database.",
      "priority": "high",
      "dependencies": [
        7
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 10,
      "title": "Develop Configuration Management System",
      "description": "Implement a configuration management system using YAML/TOML.",
      "details": "Create a configuration management system in `utils/config.py` that reads from YAML/TOML files. Ensure it supports user-specific configurations and sensible defaults.",
      "testStrategy": "Test the configuration loading functionality with various configuration files to ensure it behaves as expected.",
      "priority": "medium",
      "dependencies": [
        3
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 11,
      "title": "Implement Error Handling and Logging",
      "description": "Add comprehensive error handling and logging throughout the package.",
      "details": "Integrate logging using the `logging` module and implement error handling across all modules to ensure graceful degradation and informative error messages.",
      "testStrategy": "Simulate errors in various modules and verify that they are logged correctly and do not crash the application.",
      "priority": "medium",
      "dependencies": [
        2
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 12,
      "title": "Implement CLI Subcommands",
      "description": "Develop all CLI subcommands for analysis, query generation, and server mode.",
      "details": "Implement subcommands in `cli/analyze.py`, `cli/query.py`, and `cli/server.py` to handle respective functionalities. Use `argparse` for argument parsing.",
      "testStrategy": "Test each CLI subcommand to ensure they execute correctly and produce expected outputs.",
      "priority": "high",
      "dependencies": [
        6
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 13,
      "title": "Add Progress Indicators to CLI",
      "description": "Enhance CLI output with progress indicators and status updates.",
      "details": "Use libraries like `tqdm` (version 4.62.3) to add progress bars and status updates to long-running CLI commands.",
      "testStrategy": "Run CLI commands that take time to complete and verify that progress indicators are displayed correctly.",
      "priority": "medium",
      "dependencies": [
        12
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 14,
      "title": "Implement Batch Processing Support",
      "description": "Add support for processing multiple documents and directories in the CLI.",
      "details": "Enhance the CLI to accept multiple file inputs and directories for batch processing in `cli/analyze.py`. Implement logic to handle each file appropriately.",
      "testStrategy": "Test batch processing with various document sets to ensure all documents are processed correctly.",
      "priority": "medium",
      "dependencies": [
        12
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 15,
      "title": "Develop Output Formats for CLI",
      "description": "Implement support for multiple output formats in the CLI.",
      "details": "Add options for output formats such as JSON, YAML, and human-readable text in the CLI commands. Use libraries like `PyYAML` (version 5.4.1) for YAML support.",
      "testStrategy": "Verify that the output formats are correctly generated and match the expected structure.",
      "priority": "medium",
      "dependencies": [
        12
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 16,
      "title": "Migrate FastAPI Server to New Structure",
      "description": "Integrate the existing FastAPI server into the new package structure.",
      "details": "Move the FastAPI server code into `api/fastapi_app.py` and ensure all routes are defined in `api/routes.py`. Update the server initialization logic accordingly.",
      "testStrategy": "Run the FastAPI server and verify that all endpoints are accessible and function as expected.",
      "priority": "medium",
      "dependencies": [
        2
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 17,
      "title": "Implement API Documentation",
      "description": "Add OpenAPI/Swagger documentation for all API endpoints.",
      "details": "Use FastAPI's built-in documentation features to generate OpenAPI documentation for all endpoints. Ensure that it is accessible at `/docs` and `/redoc` paths.",
      "testStrategy": "Access the documentation endpoints and verify that all API endpoints are documented correctly.",
      "priority": "medium",
      "dependencies": [
        16
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 18,
      "title": "Add Authentication to API",
      "description": "Implement optional API key authentication for server mode.",
      "details": "Add middleware for API key authentication in the FastAPI server. Store keys securely and validate them for incoming requests.",
      "testStrategy": "Test the API with valid and invalid keys to ensure that authentication works as expected.",
      "priority": "medium",
      "dependencies": [
        16
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 19,
      "title": "Configure CORS for API",
      "description": "Set up proper CORS configuration for the API.",
      "details": "Use FastAPI's CORS middleware to configure CORS settings for the API, allowing access from specified origins.",
      "testStrategy": "Test API access from different origins to ensure CORS is configured correctly.",
      "priority": "medium",
      "dependencies": [
        16
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 20,
      "title": "Implement Health Check Endpoints",
      "description": "Add monitoring endpoints for deployment scenarios.",
      "details": "Create health check endpoints in `api/routes.py` to monitor the status of the API and its dependencies.",
      "testStrategy": "Access the health check endpoints and verify that they return the expected status.",
      "priority": "medium",
      "dependencies": [
        16
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 21,
      "title": "Bundle Web Interface with Package",
      "description": "Integrate the web interface into the package structure.",
      "details": "Move the web interface files into the `web` directory and ensure they are served correctly by the FastAPI server.",
      "testStrategy": "Run the FastAPI server and verify that the web interface is accessible and functions as expected.",
      "priority": "medium",
      "dependencies": [
        2
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 22,
      "title": "Implement Template System for Web Interface",
      "description": "Use Jinja2 templates for dynamic content in the web interface.",
      "details": "Integrate Jinja2 for rendering templates in the web interface. Ensure that dynamic content is displayed correctly.",
      "testStrategy": "Test the web interface to ensure that templates render correctly with dynamic data.",
      "priority": "medium",
      "dependencies": [
        21
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 23,
      "title": "Integrate Frontend Build Process",
      "description": "Set up a build process for the frontend assets.",
      "details": "Integrate a build process using tools like Webpack or Parcel to manage frontend assets and dependencies.",
      "testStrategy": "Run the build process and verify that all frontend assets are correctly bundled and served.",
      "priority": "medium",
      "dependencies": [
        21
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 24,
      "title": "Implement Plugin Architecture",
      "description": "Develop an extensible architecture for custom document processors.",
      "details": "Design a plugin system that allows users to create and integrate custom document processors and output formats.",
      "testStrategy": "Create sample plugins and verify that they can be loaded and executed correctly within the package.",
      "priority": "low",
      "dependencies": [
        2
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 25,
      "title": "Publish Package to PyPI",
      "description": "Automate the publishing process to the Python Package Index.",
      "details": "Set up a CI/CD pipeline to automate the process of building and publishing the package to PyPI using tools like GitHub Actions or Travis CI.",
      "testStrategy": "Verify that the package can be published to PyPI successfully and that it can be installed via `pip`.",
      "priority": "medium",
      "dependencies": [
        3
      ],
      "status": "pending",
      "subtasks": []
    },
    {
      "id": 26,
      "title": "Fix Frontend Static File Serving in FastAPI App",
      "description": "Resolve 404 errors for CSS/JS assets in the FastAPI application by properly serving static files from the frontend/dist directory. Address path confusion caused by the nested pip package within the old MSI installer project.",
      "status": "in-progress",
      "dependencies": [
        16,
        23
      ],
      "priority": "high",
      "details": "Investigate the current static file serving configuration in the FastAPI app. Ensure that the static files are correctly mapped to the /assets route. Update the FastAPI app to serve static files from the frontend/dist/assets directory. Verify that the paths for /assets/index-pUgRAzB7.js and /vite.svg are correctly set up in the FastAPI application. Test the application to ensure that the assets load correctly without returning 404 errors. Consider using FastAPI's StaticFiles middleware to serve the assets properly. Additionally, decide on one of the following actions to resolve the path confusion: 1) Move the pip package to a separate directory, 2) Fix paths in the current structure, or 3) Copy frontend files to the package web directory.",
      "testStrategy": "1. Start the FastAPI application and navigate to /app in a web browser. 2. Open the browser's developer tools and check the network tab for requests to /assets/index-pUgRAzB7.js and /vite.svg. 3. Verify that these requests return a 200 status code and that the files are loaded correctly. 4. Check the server logs to ensure no 404 errors are logged for these assets. 5. Test the application in different browsers to confirm consistent behavior.",
      "subtasks": [
        {
          "id": 1,
          "title": "Investigate static file serving configuration",
          "status": "done"
        },
        {
          "id": 2,
          "title": "Verify paths for assets",
          "status": "done"
        },
        {
          "id": 3,
          "title": "Decide on action to resolve path confusion",
          "status": "done",
          "details": "Choose one of the following options: 1) Move the pip package to a separate directory, 2) Fix paths in the current structure, or 3) Copy frontend files to the package web directory."
        },
        {
          "id": 4,
          "title": "Implement chosen action for path resolution",
          "status": "done",
          "details": "<info added on 2025-05-27T21:59:43.206Z>\n✅ COMPLETED: Frontend implementation successful!\n\n**What was accomplished:**\n- Created complete frontend structure in `frontend/dist/`\n- Built modern, responsive HTML interface (`index.html`) with:\n  - Professional legal theme with blue gradient header\n  - File upload with drag-and-drop support\n  - Document analysis section with multiple analysis types\n  - Query generation for multiple legal databases\n  - Session management and real-time feedback\n  - Loading overlays and toast notifications\n\n- Implemented comprehensive CSS styling (`assets/styles.css`) featuring:\n  - Modern card-based layout\n  - Gradient buttons with hover effects\n  - Responsive design for mobile/desktop\n  - Professional color scheme suitable for legal applications\n  - Smooth animations and transitions\n\n- Created full JavaScript application (`assets/app.js`) with:\n  - Complete API integration for all endpoints (/upload, /analyze, /query, /health)\n  - File handling with validation for PDF, DOCX, TXT\n  - Session management and state tracking\n  - Error handling and user feedback\n  - API key management with localStorage\n\n- Fixed FastAPI static file serving by adding:\n  - StaticFiles mount for `/assets` route\n  - Proper path resolution for frontend assets\n  - Logging for debugging asset serving\n\n**Frontend Features Implemented:**\n1. **File Upload**: Drag-and-drop + file browser with type validation\n2. **Document Analysis**: Multiple analysis types (summary, key points, legal issues, recommendations)\n3. **Query Generation**: Single database or all databases with confidence scoring\n4. **Session Management**: Real-time session info display\n5. **Health Monitoring**: System status checking\n6. **User Experience**: Loading states, error handling, toast notifications\n\n**Technical Implementation:**\n- Clean separation of concerns with modular JavaScript class\n- Proper error handling and user feedback\n- Responsive design that works on all devices\n- Professional styling appropriate for legal professionals\n- Complete API integration matching the FastAPI endpoints\n\nThe frontend is now fully functional and ready for testing. All static file serving issues have been resolved.\n</info added on 2025-05-27T21:59:43.206Z>\n<info added on 2025-05-27T22:10:06.067Z>\n✅ COMPLETED: Successfully migrated frontend to pip-installable structure!\n\n**What was accomplished:**\n- **Moved frontend files to proper pip location**: Migrated all frontend files from external `frontend/` directory to `lawfirm_rag/web/static/` for proper package inclusion\n- **Updated FastAPI static file serving**: Modified `fastapi_app.py` to serve static files from the new `lawfirm_rag/web/static/` location instead of external frontend directory\n- **Verified pyproject.toml package data**: Confirmed that `web/static/**/*` is already included in package data, ensuring frontend files are included when users run `pip install lawfirm-rag`\n- **Tested server functionality**: Successfully started FastAPI server and verified:\n  - Health endpoint returns: `{\"status\":\"healthy\",\"ai_engine_loaded\":false,\"query_generator_available\":true}`\n  - Frontend endpoint `/app` serves HTML (7378 characters)\n  - Static assets are properly mounted and accessible\n  - CSS and JS files are served from `/assets/` path\n\n**Current structure (pip-installable):**\n```\nlawfirm_rag/\n├── web/\n│   └── static/\n│       ├── index.html (7.2KB)\n│       └── assets/\n│           ├── styles.css (9.0KB)\n│           └── app.js (14KB)\n```\n\n**Installation behavior:**\n- When users run `pip install lawfirm-rag`, they get the complete package including frontend\n- Frontend is accessible at `http://localhost:8000/app` when running the API server\n- All static assets (CSS, JS) are properly served from the package\n\n**Next steps:** Frontend is now fully functional and pip-installable. Ready for production use!\n</info added on 2025-05-27T22:10:06.067Z>\n<info added on 2025-05-27T22:15:57.641Z>\n✅ MAJOR UPDATE: Replaced API key popup with comprehensive Model Management system!\n\n**What was accomplished:**\n- **Removed API key popup**: Eliminated the intrusive API key prompt that was blocking user access\n- **Added Model Management Modal**: Created a professional modal interface accessible via \"Model Management\" button in header and status banner\n- **Featured Law Chat GGUF Model**: Prominently displayed the recommended [Law Chat GGUF model](https://huggingface.co/TheBloke/law-chat-GGUF) with:\n  - Q4_0 variant (3.83 GB) as the recommended option\n  - Complete model information (size, type, description, source link)\n  - Download functionality with progress tracking\n  - \"Other Sizes\" button to show all available quantizations (Q2_K, Q3_K_M, Q4_0, Q5_0, Q8_0)\n\n- **Model Status Integration**: \n  - Status banner shows current model state (\"No AI model loaded - Using fallback mode\")\n  - Real-time status updates when models are downloaded\n  - Visual indicators (colored status dots) for quick status recognition\n  - Integration with health check system\n\n- **Enhanced UI Features**:\n  - Professional model cards with badges (\"Recommended\", \"Future\")\n  - Detailed variant comparison grid with sizes and quality descriptions\n  - Simulated download progress bars with percentage indicators\n  - Responsive design for mobile and desktop\n  - Toast notifications for user feedback\n\n- **Improved User Experience**:\n  - No more blocking popups - users can immediately access the application\n  - Clear path to model acquisition through dedicated management interface\n  - Fallback mode allows basic functionality without AI models\n  - Professional legal-themed design consistent with application purpose\n\n**Technical Implementation**:\n- Updated HTML structure with modal and status components\n- Enhanced CSS with model management specific styles\n- Refactored JavaScript to remove API key dependency and add model management logic\n- Maintained all existing functionality while improving accessibility\n\nThe frontend now provides a much better user experience with clear model management capabilities and no blocking popups!\n</info added on 2025-05-27T22:15:57.641Z>"
        }
      ]
    },
    {
      "id": 27,
      "title": "Implement Hugging Face Model Download Functionality",
      "description": "Implement real model downloading from Hugging Face for the Law Chat GGUF model, replacing the simulated download in the frontend with actual downloading functionality.",
      "status": "done",
      "dependencies": [
        8,
        16,
        17
      ],
      "priority": "high",
      "details": "1. Create a new module `model_downloader.py` in the `core` directory.\n\n2. Implement a `ModelDownloader` class with the following methods:\n   - `download_model(model_variant: str) -> bool`: Main method to handle the download process\n   - `get_download_url(model_variant: str) -> str`: Generate the correct Hugging Face URL\n   - `track_progress(response: requests.Response, total_size: int)`: Generator to track download progress\n   - `validate_downloaded_file(file_path: str) -> bool`: Verify the integrity of the downloaded file\n   - `is_model_downloaded(model_variant: str) -> bool`: Check if model already exists and is valid\n   - `get_download_progress() -> dict`: Get current download status\n   - `cancel_download() -> bool`: Cancel ongoing downloads\n   - `list_available_models() -> list`: List all supported model variants\n   - `cleanup_failed_downloads() -> bool`: Clean up temporary files\n\n3. In the backend API (`api/fastapi_app.py`), create new endpoints:\n   - GET `/models/available`: Lists all available models with download status\n   - POST `/models/download`: Starts model download with background processing\n   - GET `/models/download-progress`: Provides real-time download progress\n   - POST `/models/cancel-download`: Cancels ongoing downloads\n   - DELETE `/models/cleanup`: Cleans up failed/temporary downloads\n\n4. Update the frontend (`web/static/assets/app.js`) to:\n   - Replace simulated download with real download API calls\n   - Implement real-time progress tracking with speed (MB/s) and ETA\n   - Add download cancellation functionality with cancel button\n   - Handle and display download errors\n   - Update model status upon successful download\n\n5. Modify `core/config.py` to include:\n   - `MODEL_STORAGE_DIR`: Path to store downloaded models\n   - `SUPPORTED_MODEL_VARIANTS`: List of supported model variants with sizes\n\n6. Implement error handling and logging in `model_downloader.py`:\n   - Network errors\n   - Insufficient disk space\n   - Invalid model variant\n   - Custom `ModelDownloadError` exception with detailed error messages\n\n7. Update `core/model_manager.py` to integrate with the new download functionality:\n   - Use `ModelDownloader` for fetching new models\n   - Update model status in the database after successful download\n   - Auto-initialize AI components after successful downloads\n\n8. Implement file validation after download:\n   - Check file size (with 5% tolerance)\n   - Verify GGUF format using magic bytes verification\n\n9. Add unit tests for the `ModelDownloader` class in `tests/test_model_downloader.py`\n\n10. Update API documentation to include new endpoints related to model downloading.",
      "testStrategy": "1. Unit Tests:\n   - Test `get_download_url` method with various model variants\n   - Mock download process to test progress tracking\n   - Test file validation method with both valid and invalid files\n   - Test error handling for network issues and invalid variants\n   - Verify GGUF magic bytes validation works correctly\n\n2. Integration Tests:\n   - Test the entire download process end-to-end\n   - Verify correct storage of downloaded models\n   - Check database updates after successful downloads\n   - Test auto-initialization of AI components after download\n\n3. API Tests:\n   - Test all five new endpoints for model management\n   - Verify correct responses and error handling\n   - Test background task processing for downloads\n   - Verify cancellation functionality works properly\n\n4. Frontend Tests:\n   - Test UI updates during download process\n   - Verify error message display for failed downloads\n   - Check model status updates after successful downloads\n   - Test cancellation button functionality\n   - Verify progress display shows speed and ETA correctly\n\n5. Manual Testing:\n   - Attempt downloads with different network conditions\n   - Verify progress bar accuracy\n   - Test cancellation of ongoing downloads\n   - Check behavior with insufficient disk space\n   - Verify toast notifications for all major events\n\n6. Performance Testing:\n   - Measure download speeds for different model sizes\n   - Test memory usage during large file downloads\n   - Verify chunked reading (8KB chunks) works efficiently\n\n7. Security Testing:\n   - Ensure downloaded files are stored securely\n   - Verify that only authorized users can trigger downloads\n   - Test API key authentication for download endpoints\n\n8. Compatibility Testing:\n   - Test functionality across different browsers and devices\n   - Verify downloads work for all supported model variants (Q2_K, Q3_K_M, Q4_0, Q5_0, Q8_0)",
      "subtasks": [
        {
          "id": 1,
          "title": "Create ModelDownloader class",
          "description": "Implement the ModelDownloader class in model_downloader.py with methods for downloading, URL generation, progress tracking, and file validation.",
          "dependencies": [],
          "details": "Create model_downloader.py in the core directory. Implement ModelDownloader class with methods: download_model, get_download_url, track_progress, and validate_downloaded_file. Include error handling for network issues, disk space, and invalid model variants.\n<info added on 2025-05-27T22:28:52.189Z>\n✅ COMPLETED: ModelDownloader class implementation\n\n**What was accomplished:**\n- Created comprehensive `ModelDownloader` class in `lawfirm_rag/core/model_downloader.py`\n- Implemented all required methods:\n  - `download_model()`: Main download method with proper error handling\n  - `get_download_url()`: Generates correct Hugging Face URLs for all model variants\n  - `track_progress()`: Real-time progress tracking with speed and ETA calculations\n  - `validate_downloaded_file()`: File validation including size checks and GGUF format validation\n  - `is_model_downloaded()`: Check if model already exists and is valid\n  - `get_download_progress()`: Get current download status\n  - `cancel_download()`: Cancel ongoing downloads\n  - `list_available_models()`: List all supported model variants\n  - `cleanup_failed_downloads()`: Clean up temporary files\n\n**Key Features Implemented:**\n- **Proper Hugging Face URLs**: Uses correct format `https://huggingface.co/TheBloke/law-chat-GGUF/resolve/main/{filename}?download=true`\n- **All Model Variants Supported**: Q2_K, Q3_K_M, Q4_0, Q5_0, Q8_0 with correct filenames and expected sizes\n- **Progress Tracking**: Real-time progress with speed, ETA, and percentage completion\n- **File Validation**: Size validation (5% tolerance) and GGUF magic bytes verification\n- **Error Handling**: Custom `ModelDownloadError` exception with detailed error messages\n- **Temporary Files**: Uses `.tmp` extension during download, renamed on completion\n- **Storage Management**: Creates `models/downloaded/` directory automatically\n- **Session Management**: Proper HTTP session with User-Agent header\n\n**Technical Implementation:**\n- Uses `requests` with streaming for large file downloads\n- Implements chunked reading (8KB chunks) for memory efficiency\n- Progress updates every 0.5 seconds to avoid excessive UI updates\n- Comprehensive logging for debugging and monitoring\n- Thread-safe progress tracking with internal state management\n\n**File Structure:**\n```\nlawfirm_rag/\n├── core/\n│   ├── model_downloader.py (new - 350+ lines)\n│   └── __init__.py (updated with imports)\n└── models/\n    └── downloaded/ (created automatically)\n```\n</info added on 2025-05-27T22:28:52.189Z>",
          "status": "done",
          "testStrategy": "Write unit tests in tests/test_model_downloader.py to verify each method of the ModelDownloader class."
        },
        {
          "id": 2,
          "title": "Update backend API",
          "description": "Create new endpoints in api/routes.py for model download and progress tracking.",
          "dependencies": [
            1
          ],
          "details": "Add POST /api/models/download endpoint to trigger model download. Implement GET /api/models/download-progress endpoint to retrieve current download progress. Ensure proper error handling and response formatting.\n<info added on 2025-05-27T22:30:35.270Z>\nI've implemented comprehensive model download API endpoints in `lawfirm_rag/api/fastapi_app.py`:\n\n- `GET /models/available`: Lists all available models with download status\n- `POST /models/download`: Starts model download with background processing\n- `GET /models/download-progress`: Provides real-time download progress\n- `POST /models/cancel-download`: Cancels ongoing downloads\n- `DELETE /models/cleanup`: Cleans up failed/temporary downloads\n\nCreated Pydantic models for request/response handling:\n- `ModelDownloadRequest`, `ModelDownloadResponse`, `ModelProgressResponse`, `ModelListResponse`\n\nImplemented robust download logic with:\n- Background downloads using FastAPI BackgroundTasks\n- Validation for supported model variants\n- Prevention of duplicate downloads\n- Conflict handling (one download at a time)\n- Auto-initialization of AI components after successful download\n- Comprehensive error handling with appropriate HTTP status codes\n\nKey features include real-time progress tracking, force download option, download cancellation, cleanup functionality, status management, and API key authentication.\n\nAll endpoints use proper HTTP status codes and include comprehensive logging for debugging and monitoring.\n</info added on 2025-05-27T22:30:35.270Z>",
          "status": "done",
          "testStrategy": "Create integration tests to verify the new API endpoints function correctly with the ModelDownloader class."
        },
        {
          "id": 3,
          "title": "Modify frontend for real downloads",
          "description": "Update ModelManager.vue to use real download API calls and implement progress tracking.",
          "dependencies": [
            2
          ],
          "details": "Replace simulated download in web/src/components/ModelManager.vue with real API calls. Implement progress tracking using the new download-progress endpoint. Add error handling and display for download issues. Update model status display upon successful download.\n<info added on 2025-05-27T22:32:26.780Z>\nThe frontend integration for real model downloads has been completed. The simulated download in web/src/components/ModelManager.vue has been replaced with real API calls to the backend endpoints. Key implementations include:\n\n- Real API integration with `/models/download` and `/models/download-progress` endpoints in `lawfirm_rag/web/static/assets/app.js`\n- Real-time progress tracking showing download percentage, speed (MB/s), and estimated time remaining\n- Download cancellation functionality via the `/models/cancel-download` endpoint with a dedicated cancel button\n- Comprehensive error handling for various download failure scenarios\n- Enhanced UI with improved progress display, status management, and visual feedback\n- Smart polling system that updates progress every second during active downloads\n- Proper cleanup of progress intervals and error recovery mechanisms\n- Automatic model status updates after successful downloads\n\nThe implementation maintains responsive design principles and includes appropriate styling for all new UI elements. All download states (idle, downloading, completed, error, cancelled) are properly handled with clear visual feedback to the user.\n</info added on 2025-05-27T22:32:26.780Z>",
          "status": "done",
          "testStrategy": "Perform end-to-end testing to ensure the frontend correctly interacts with the new backend endpoints and displays download progress accurately."
        },
        {
          "id": 4,
          "title": "Update configuration and model management",
          "description": "Modify config.py and model_manager.py to support the new download functionality.",
          "dependencies": [
            1
          ],
          "details": "Add MODEL_STORAGE_DIR and SUPPORTED_MODEL_VARIANTS to core/config.py. Update core/model_manager.py to use ModelDownloader for fetching new models and update model status in the database after successful download. Implement auto-initialization of AI components after successful downloads. Configure model variants with their respective sizes: Q2_K (2.83GB), Q3_K_M (3.30GB), Q4_0 (3.83GB), Q5_0 (4.65GB), Q8_0 (7.16GB).",
          "status": "done",
          "testStrategy": "Write unit tests to verify the correct configuration is loaded and that the model manager properly integrates with the ModelDownloader class. Test auto-initialization of AI components after successful downloads."
        },
        {
          "id": 5,
          "title": "Implement file validation and update documentation",
          "description": "Add post-download file validation and update API documentation for new endpoints.",
          "dependencies": [
            1,
            2,
            4
          ],
          "details": "Implement file size check (with 5% tolerance) and GGUF format validation using magic bytes verification after download. Update API documentation to include details about all five new model download endpoints: `/models/available`, `/models/download`, `/models/download-progress`, `/models/cancel-download`, and `/models/cleanup`. Document the Pydantic models used for request/response handling.",
          "status": "done",
          "testStrategy": "Create unit tests for file validation functions including GGUF magic bytes verification. Review and verify the updated API documentation for accuracy and completeness for all five new endpoints."
        },
        {
          "id": 6,
          "title": "Implement comprehensive error handling and logging",
          "description": "Enhance error handling and logging throughout the model download system.",
          "dependencies": [
            1,
            2,
            3
          ],
          "details": "Implement comprehensive error handling for various download scenarios including network errors, insufficient disk space, invalid model variants, and interrupted downloads. Create a custom ModelDownloadError exception with detailed error messages. Add thorough logging throughout the download process for debugging and monitoring purposes. Ensure proper cleanup of temporary files in error scenarios.",
          "status": "done",
          "testStrategy": "Test error handling by simulating various failure scenarios including network interruptions, disk space issues, and invalid model requests. Verify logs contain appropriate information for debugging and monitoring."
        },
        {
          "id": 7,
          "title": "Optimize download performance and memory usage",
          "description": "Optimize the download process for large model files to ensure efficient memory usage and reliable downloads.",
          "dependencies": [
            1,
            2
          ],
          "details": "Implement chunked reading (8KB chunks) for memory-efficient downloads of large model files. Optimize progress tracking to update at appropriate intervals (e.g., every 0.5 seconds) to avoid excessive UI updates. Implement proper HTTP session management with appropriate headers. Test and optimize download performance across different network conditions.",
          "status": "done",
          "testStrategy": "Measure memory usage during large file downloads to verify efficient chunked reading. Test download performance under various network conditions. Verify progress updates occur at appropriate intervals without overwhelming the UI."
        }
      ]
    },
    {
      "id": 28,
      "title": "Implement Model Loading and Selection Functionality",
      "description": "Develop a system to load and select downloaded GGUF models, connecting them to the AI engine. This includes backend API, frontend UI, and integration with the existing AIEngine class.",
      "status": "completed",
      "dependencies": [
        27,
        9,
        17,
        12,
        11
      ],
      "priority": "high",
      "details": "1. Backend Model Loading API:\n   - Create new endpoints in the FastAPI server (e.g., `/api/models/load`, `/api/models/unload`, `/api/models/list`)\n   - Implement functions to load and unload models from the downloaded models directory\n   - Use the `llama_cpp` library to handle GGUF model loading\n\n2. Model Discovery:\n   - Create a function to scan the downloaded models directory and detect available GGUF models\n   - Store model metadata (name, path, size) in the SQLite database\n\n3. Frontend Model Selection:\n   - Extend the existing Model Management modal in the frontend\n   - Add a dropdown or list to display available models\n   - Implement buttons for loading/unloading models\n   - Use AJAX calls to interact with the backend API\n\n4. AI Engine Integration:\n   - Modify the AIEngine class to support dynamic model loading\n   - Add methods to switch between loaded models\n   - Ensure proper initialization and cleanup of models\n\n5. Status Updates:\n   - Implement a WebSocket connection for real-time status updates\n   - Send model loading progress and status to the frontend\n   - Update UI indicators when models are loaded/unloaded\n\n6. Error Handling:\n   - Implement try-except blocks for model loading operations\n   - Create custom exceptions for various failure scenarios (e.g., InvalidModelError, ModelLoadError)\n   - Display user-friendly error messages in the frontend\n\n7. Memory Management:\n   - Implement a mechanism to unload models from memory when switching\n   - Use Python's garbage collection to ensure proper cleanup\n   - Monitor and limit the number of simultaneously loaded models based on available system resources\n\n8. Configuration:\n   - Add new configuration options for model directory path and maximum loaded models\n   - Update the configuration file and parsing logic\n\n9. CLI Integration:\n   - Extend the CLI to support model loading and unloading operations\n   - Add a new subcommand for model management (e.g., `lawchat models list`, `lawchat models load &lt;model_name&gt;`)\n\n10. Documentation:\n    - Update API documentation to include new model management endpoints\n    - Add user guide sections for model loading and selection\n    - Include developer documentation on extending the model loading functionality",
      "testStrategy": "1. Unit Tests:\n   - Write tests for model discovery function\n   - Test model loading/unloading functions with mock GGUF files\n   - Verify AIEngine class modifications\n\n2. Integration Tests:\n   - Test the interaction between backend API and SQLite storage\n   - Verify proper integration of model loading with the AI engine\n\n3. API Tests:\n   - Use pytest to test new API endpoints\n   - Verify correct responses for various scenarios (success, failure, invalid input)\n\n4. Frontend Tests:\n   - Use Jest and React Testing Library to test new UI components\n   - Verify correct rendering of model list and status indicators\n\n5. End-to-End Tests:\n   - Create Selenium or Cypress tests to simulate user interactions\n   - Test the complete flow of discovering, loading, and using a model\n\n6. Performance Tests:\n   - Measure memory usage during model loading and switching\n   - Test with multiple large models to ensure efficient resource management\n\n7. Error Handling Tests:\n   - Simulate various error conditions (e.g., corrupt model file, insufficient memory)\n   - Verify appropriate error messages are displayed\n\n8. CLI Tests:\n   - Test new CLI commands for model management\n   - Verify correct output and error handling\n\n9. Documentation Review:\n   - Ensure all new functionality is properly documented\n   - Verify accuracy of API documentation and user guide\n\n10. Manual Testing:\n    - Perform manual tests with real GGUF models\n    - Verify smooth user experience in the frontend\n    - Test edge cases and potential user mistakes",
      "subtasks": [
        {
          "id": 1,
          "title": "Implement Backend Model Loading API",
          "description": "Create new endpoints in the FastAPI server for model management and implement functions to load and unload models.",
          "dependencies": [],
          "details": "Create endpoints: `/api/models/load`, `/api/models/unload`, `/api/models/list`. Implement functions using `llama_cpp` library to handle GGUF model loading. Ensure proper error handling and status updates.\n<info added on 2025-05-27T22:40:41.029Z>\n✅ COMPLETED: Backend Model Loading API Implementation\n\n**What was accomplished:**\n\n1. **Created comprehensive ModelManager class** (`lawfirm_rag/core/model_manager.py`):\n   - **Thread-safe model management** with proper locking mechanisms\n   - **Memory management**: Automatic unloading of oldest models when memory limits reached\n   - **Model discovery**: Integration with ModelDownloader to find downloaded models\n   - **Multiple model support**: Can load/unload/switch between multiple models\n   - **Status tracking**: Comprehensive status reporting and memory usage estimation\n\n2. **Added new Pydantic models** for API responses:\n   - `ModelLoadRequest`: For model loading requests with force_reload option\n   - `ModelLoadResponse`: Standardized responses for load operations\n   - `LoadedModelInfo`: Detailed information about loaded models\n   - `LoadedModelsResponse`: Complete status of all loaded models\n\n3. **Implemented comprehensive API endpoints**:\n   - `GET /models/loaded`: Get information about currently loaded models\n   - `POST /models/load`: Load a downloaded model into memory\n   - `POST /models/unload`: Unload a model from memory\n   - `POST /models/switch`: Switch active model without unloading others\n\n4. **Enhanced existing endpoints**:\n   - Updated `/health` endpoint to include model manager status\n   - Updated `/models` endpoint to use new ModelManager instead of old implementation\n\n5. **Global AI component integration**:\n   - Model loading automatically updates global `ai_engine` and `query_generator`\n   - Proper fallback handling when no models are loaded\n   - Seamless integration with existing analysis and query endpoints\n\n**Key Features:**\n- **Memory-aware loading**: Prevents system overload by limiting concurrent models\n- **Automatic cleanup**: Unloads oldest models when memory limits are reached\n- **Thread safety**: All operations are thread-safe for concurrent requests\n- **Error handling**: Comprehensive error handling with proper HTTP status codes\n- **Status reporting**: Real-time status of loaded models, memory usage, and active model\n</info added on 2025-05-27T22:40:41.029Z>",
          "status": "done",
          "testStrategy": "Write unit tests for each API endpoint, including success and error scenarios. Test with mock GGUF models."
        },
        {
          "id": 2,
          "title": "Develop Model Discovery System",
          "description": "Create a function to scan the downloaded models directory and store model metadata in the SQLite database.",
          "dependencies": [],
          "details": "Implement a function to detect available GGUF models in the specified directory. Store model name, path, and size in the SQLite database. Ensure periodic rescanning to detect new or removed models.",
          "status": "completed",
          "testStrategy": "Create test cases with sample GGUF files and verify correct detection and database storage."
        },
        {
          "id": 3,
          "title": "Extend Frontend for Model Selection",
          "description": "Modify the existing Model Management modal to include model selection functionality and integrate with backend API.",
          "dependencies": [
            1,
            2
          ],
          "details": "Add a dropdown or list to display available models. Implement load/unload buttons. Use AJAX calls to interact with the backend API. Update UI indicators for model status.\n<info added on 2025-05-27T22:42:42.356Z>\n**Enhanced Model Management Modal Implementation**\n\n- Created comprehensive UI for model management with sections for loaded and available models\n- Implemented dynamic button states that transition between Download and Load based on model status\n- Added visual indicators for active models using green gradient styling and badges\n- Integrated memory usage display and load time tracking for each model\n\n**JavaScript Functionality**\n- Developed core model management methods: loadModel(), unloadModel(), switchToModel()\n- Created UI update functions: updateLoadedModelsDisplay(), updateDownloadedModelsDisplay()\n- Implemented dynamic UI generation with createLoadedModelsSection() and displayLoadedModels()\n- Added real-time status updates and synchronization with backend state\n\n**User Experience Improvements**\n- Implemented toast notifications for all model operations\n- Added comprehensive error handling for failed operations\n- Created hover effects and visual feedback for interactive elements\n- Ensured seamless integration with existing download functionality\n\n**CSS Enhancements**\n- Styled loaded models section with proper spacing and borders\n- Created distinctive styling for active models\n- Implemented consistent button styling across all model actions\n- Added responsive design elements for better usability\n</info added on 2025-05-27T22:42:42.356Z>",
          "status": "done",
          "testStrategy": "Perform end-to-end testing of the frontend, including UI interactions and API integration."
        },
        {
          "id": 4,
          "title": "Integrate Dynamic Model Loading with AI Engine",
          "description": "Modify the AIEngine class to support dynamic model loading and switching between loaded models.",
          "dependencies": [
            1
          ],
          "details": "Add methods to switch between loaded models. Ensure proper initialization and cleanup of models. Implement memory management to unload models when switching.",
          "status": "completed",
          "testStrategy": "Write unit tests for AIEngine class methods, focusing on model switching and memory management."
        },
        {
          "id": 5,
          "title": "Implement Real-time Status Updates",
          "description": "Create a WebSocket connection for sending real-time model loading progress and status updates to the frontend.",
          "dependencies": [
            1,
            3,
            4
          ],
          "details": "Implement WebSocket connection in both backend and frontend. Send model loading progress and status updates. Update UI indicators when models are loaded/unloaded.",
          "status": "completed",
          "testStrategy": "Test WebSocket connection stability and accuracy of status updates under various network conditions."
        }
      ]
    },
    {
      "id": 29,
      "title": "Fix File Upload Lambda Bug in FastAPI Endpoint",
      "description": "Replace the lambda function with a proper FileObj class in the FastAPI endpoint to correctly handle file processing and uploads.",
      "details": "The current implementation uses a lambda function for file processing in the FastAPI endpoint, which is causing bugs in file upload functionality. This task involves:\n\n1. Identify the problematic endpoint in the FastAPI server (likely in `api/routes.py`)\n2. Replace the lambda function with a proper FileObj class that:\n   - Properly handles file metadata (name, size, type)\n   - Manages file I/O operations safely\n   - Implements proper error handling for file operations\n   - Ensures proper cleanup of temporary files\n   - Handles different file types consistently\n\n3. Update the endpoint to use the new FileObj class:\n```python\n# Current problematic implementation (example)\n@router.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    processor = lambda f: process_document(f.filename, f.file)\n    result = await processor(file)\n    return {\"status\": \"success\", \"result\": result}\n\n# New implementation with FileObj class\nclass FileObj:\n    def __init__(self, file: UploadFile):\n        self.file = file\n        self.filename = file.filename\n        self.content_type = file.content_type\n        \n    async def process(self):\n        # Proper file handling logic\n        try:\n            # File processing code\n            return processed_result\n        except Exception as e:\n            logger.error(f\"Error processing file {self.filename}: {str(e)}\")\n            raise HTTPException(status_code=500, detail=f\"File processing error: {str(e)}\")\n        finally:\n            # Cleanup code\n\n@router.post(\"/upload\")\nasync def upload_file(file: UploadFile = File(...)):\n    file_obj = FileObj(file)\n    result = await file_obj.process()\n    return {\"status\": \"success\", \"result\": result}\n```\n\n4. Ensure the new implementation integrates correctly with the document processing module\n5. Update any related error handling to use the proper FastAPI error handling patterns\n6. Add appropriate logging for file upload operations and errors",
      "testStrategy": "1. Unit tests:\n   - Create unit tests for the new FileObj class to verify it handles various file types correctly\n   - Test error conditions (invalid files, corrupted files, etc.)\n   - Test with mock file objects to ensure proper method calls\n\n2. Integration tests:\n   - Test the endpoint with actual file uploads of different types (PDF, DOCX, TXT)\n   - Verify the endpoint correctly processes files and returns appropriate responses\n   - Test with large files to ensure proper handling of memory and resources\n   - Test concurrent uploads to verify thread safety\n\n3. Manual testing:\n   - Use the Swagger UI to upload files through the API endpoint\n   - Verify the frontend can successfully upload files through this endpoint\n   - Check logs to ensure proper error reporting\n   - Verify temporary files are properly cleaned up after processing\n\n4. Regression testing:\n   - Ensure all existing functionality that depends on file uploads still works correctly\n   - Verify that the document processing pipeline functions correctly with the new implementation",
      "status": "done",
      "dependencies": [
        7,
        16
      ],
      "priority": "high",
      "subtasks": []
    },
    {
      "id": 30,
      "title": "Fix AI Model Output Formatting and Query Generation",
      "description": "Improve AI model output formatting by removing [/INST] tags, enhance Westlaw query syntax prompts, and fix confidence scoring in responses.",
      "details": "This task involves several improvements to the AI model output and query generation:\n\n1. Remove [/INST] tags from AI responses:\n   - Identify where these instruction tags are leaking into the final output\n   - Implement a post-processing filter in the AIEngine class to strip these tags\n   - Ensure the filter handles various formats of instruction tags ([/INST], [INST], etc.)\n\n2. Improve Westlaw query syntax prompts:\n   - Review current prompt templates for Westlaw query generation\n   - Enhance prompts to better guide the model in generating syntactically correct Westlaw queries\n   - Add examples of well-formed Westlaw queries in the prompt templates\n   - Implement syntax validation for generated queries\n   - Create a specialized prompt template specifically for legal research queries\n\n3. Fix confidence scoring:\n   - Review the current implementation of confidence scoring\n   - Identify issues in the calculation or presentation of confidence scores\n   - Implement a more reliable algorithm for determining confidence scores\n   - Normalize confidence scores to a consistent scale (e.g., 0-100%)\n   - Add metadata to responses that explains the basis for confidence scores\n\n4. Implementation steps:\n   - Update the AIEngine class in the core module to handle these improvements\n   - Modify the prompt templates in the templates directory\n   - Update the response processing pipeline to clean outputs\n   - Add unit tests for each improvement\n   - Document the changes in code comments and update API documentation\n\n5. Integration considerations:\n   - Ensure changes are backward compatible with existing API calls\n   - Update any frontend components that display confidence scores\n   - Consider adding a configuration option to toggle the new formatting features",
      "testStrategy": "1. Test removal of instruction tags:\n   - Create unit tests with sample AI responses containing [/INST] tags\n   - Verify the post-processing correctly removes all variants of instruction tags\n   - Test with various edge cases (nested tags, malformed tags, etc.)\n\n2. Test Westlaw query generation:\n   - Create a test suite with legal research scenarios\n   - Compare generated queries before and after the improvements\n   - Verify syntax correctness of generated queries\n   - Test with a variety of legal topics and complexity levels\n   - Validate that generated queries work correctly when submitted to Westlaw\n\n3. Test confidence scoring:\n   - Create test cases with known expected confidence levels\n   - Verify scores are calculated correctly and consistently\n   - Test edge cases (very high/low confidence scenarios)\n   - Ensure confidence scores correlate with actual response quality\n\n4. Integration testing:\n   - Test the complete pipeline from user input to final formatted output\n   - Verify CLI output displays correctly with the improvements\n   - Test API endpoints return properly formatted responses\n   - Verify frontend components display the improved outputs correctly\n\n5. Performance testing:\n   - Measure any impact on response time from the additional processing\n   - Ensure the improvements don't significantly increase memory usage\n\n6. Manual verification:\n   - Conduct user testing to verify the improvements enhance usability\n   - Compare side-by-side outputs from before and after the changes",
      "status": "done",
      "dependencies": [
        8,
        15,
        28
      ],
      "priority": "high",
      "subtasks": []
    },
    {
      "id": 31,
      "title": "Set up GitHub Repository for lawfirm-rag-package",
      "description": "Create a remote GitHub repository for the LawFirm-RAG project, configure the local repository to connect to the remote origin, and push the initial codebase.",
      "status": "done",
      "dependencies": [
        1,
        3,
        5
      ],
      "priority": "medium",
      "details": "1. Create a new repository on GitHub:\n   - Log in to GitHub and create a new repository named \"lawfirm-rag-package\"\n   - Keep the repository private initially (can be changed later)\n   - Do not initialize with README, .gitignore, or license (these already exist locally)\n\n2. Configure the local repository to connect to the remote:\n   - Navigate to the local project directory\n   - Run `git remote add origin https://github.com/username/lawfirm-rag-package.git`\n   - Verify the remote connection with `git remote -v`\n\n3. Push the codebase to GitHub:\n   - The local repository is already initialized with main branch, README.md, MIT License, and .gitignore\n   - Ensure all necessary files are staged: `git add .`\n   - Create an initial commit with a descriptive message: `git commit -m \"Initial commit: LawFirm-RAG package structure\"`\n   - Set the upstream branch: `git push -u origin main`\n   - Verify the push was successful by checking the GitHub repository\n\n4. Configure branch protection rules (optional):\n   - Set up branch protection for the main branch\n   - Require pull request reviews before merging\n   - Require status checks to pass before merging\n\n5. Set up GitHub Actions workflow (optional):\n   - Create a `.github/workflows` directory\n   - Add a basic CI workflow YAML file for testing\n\n6. Update documentation with repository information:\n   - Add the repository URL to the README.md if not already included\n   - Include basic clone instructions for contributors",
      "testStrategy": "1. Verify the GitHub repository exists and is accessible:\n   - Navigate to the GitHub repository URL\n   - Confirm the repository name matches \"lawfirm-rag-package\"\n   - Verify repository visibility settings are as expected\n\n2. Confirm remote configuration:\n   - Run `git remote -v` in the local repository\n   - Verify that the origin points to the correct GitHub URL\n\n3. Validate the initial codebase push:\n   - Check that all files from the local repository appear in the GitHub repository\n   - Verify file structure matches the expected project layout\n   - Confirm that the comprehensive README.md, MIT License, and Python-specific .gitignore are present\n   - Confirm that .gitignore is working correctly (no unwanted files in repository)\n\n4. Test clone functionality:\n   - Clone the repository to a new location using `git clone https://github.com/username/lawfirm-rag-package.git`\n   - Verify all files are correctly cloned\n\n5. Verify branch configuration:\n   - Confirm the default branch is set correctly (main)\n   - Check that any branch protection rules are functioning as expected\n\n6. Document verification:\n   - Ensure README.md contains the correct repository URL\n   - Verify installation instructions work when following them from the GitHub repository",
      "subtasks": [
        {
          "id": 31.1,
          "title": "Local repository preparation",
          "description": "Git repository has been initialized with main branch, comprehensive README.md created, MIT License added, and .gitignore configured for Python project.",
          "status": "done"
        },
        {
          "id": 31.2,
          "title": "Create GitHub repository",
          "description": "Create the 'lawfirm-rag-package' repository on GitHub without initializing README, license or gitignore since these already exist locally.",
          "status": "done"
        },
        {
          "id": 31.3,
          "title": "Connect and push to remote repository",
          "description": "Connect the local repository to GitHub remote and push the initial codebase.",
          "status": "done"
        },
        {
          "id": 31.4,
          "title": "Configure repository settings",
          "description": "Set up branch protection rules and other repository settings as needed.",
          "status": "done"
        }
      ]
    },
    {
      "id": 32,
      "title": "Set up GitHub Packages for Private Distribution",
      "description": "Configure GitHub Actions workflow to publish the lawfirm-rag-package to PyPI instead of GitHub Packages, and update package configuration for public distribution.",
      "status": "in-progress",
      "dependencies": [
        31,
        25,
        3
      ],
      "priority": "high",
      "details": "1. Configure package for PyPI distribution:\n   - Update the `pyproject.toml` file to include PyPI repository information and update package name to match PyPI naming convention:\n     ```toml\n     [build-system]\n     requires = [\"setuptools>=42\", \"wheel\"]\n     build-backend = \"setuptools.build_meta\"\n\n     # Update package name to 'lawfirm-rag-package' to match PyPI naming convention\n     ```\n\n2. Create or modify the GitHub Actions workflow file (`.github/workflows/publish-to-pypi.yml`):\n   ```yaml\n   name: Publish Python Package to PyPI\n\n   on:\n     release:\n       types: [created]\n     # Optional: Add manual trigger\n     workflow_dispatch:\n\n   jobs:\n     deploy:\n       runs-on: ubuntu-latest\n       environment: release\n       permissions:\n         id-token: write  # Required for PyPI trusted publishing\n         contents: read\n       steps:\n       - uses: actions/checkout@v3\n       - name: Set up Python\n         uses: actions/setup-python@v4\n         with:\n           python-version: '3.10'\n       - name: Install dependencies\n         run: |\n           python -m pip install --upgrade pip\n           pip install build\n       - name: Build package\n         run: python -m build\n       - name: Publish package to PyPI\n         uses: pypa/gh-action-pypi-publish@release/v1\n   ```\n\n3. Set up PyPI account and token:\n   - Create a PyPI account if you don't have one\n   - Generate a PyPI API token with upload scope specifically for \"Upload to project: lawfirm-rag-package\"\n   - Add the token to GitHub repository secrets as PYPI_API_TOKEN\n\n4. Create documentation for users on how to install the package:\n   ```markdown\n   ## Installing from PyPI\n\n   To install this package from PyPI, simply run:\n\n   ```\n   pip install lawfirm-rag-package\n   ```\n   ```\n\n5. Update the README.md with installation instructions for public package distribution:\n   - Include documentation for installing from PyPI\n   - Remove any references to GitHub Packages or private distribution\n\n6. Test the workflow by creating a GitHub release or using the manual workflow trigger.\n\nNote: This approach is preferable as:\n- PyPI is the standard Python package registry\n- Public packages on PyPI are freely available without authentication\n- PyPI has better integration with pip and Python tooling\n- PyPI packages are easier to install for end users\n- The workflow uses PyPI's trusted publishing mechanism, which is more secure than using API tokens directly in the workflow",
      "testStrategy": "1. Verify PyPI configuration:\n   - Check that the `pyproject.toml` file has been correctly updated with PyPI repository information and the package name has been changed to 'lawfirm-rag-package'\n   - Ensure the GitHub Actions workflow file is properly configured to publish to PyPI with appropriate permissions and environment settings\n\n2. Test the GitHub Actions workflow:\n   - Create a test release tag or use the manual workflow trigger\n   - Monitor the GitHub Actions workflow execution\n   - Verify that the package is successfully built and published to PyPI\n\n3. Test package installation:\n   - Create a new virtual environment\n   - Attempt to install the package using pip directly from PyPI\n   - Verify that the package installs correctly and can be imported\n   - Ensure the package can be installed using the name 'lawfirm-rag-package'\n\n4. Test access controls (if needed):\n   - If the package should be public, verify that anyone can access and install it\n   - If the package should be private, verify that only authorized users can access it\n\n5. Integration testing:\n   - Create a simple test project that depends on the package\n   - Verify that the package can be installed and used in a real project scenario\n   - Test any specific functionality that might be affected by the distribution method\n\n6. Documentation verification:\n   - Review the updated README and documentation\n   - Ensure the installation instructions are clear and accurate\n   - Have a team member follow the instructions to verify they work as expected\n   - Confirm the documentation reflects the new package name and PyPI installation method",
      "subtasks": [
        {
          "id": "32.1",
          "title": "Test GitHub release workflow",
          "description": "Create a GitHub release to test the publishing workflow and verify the package is correctly published to GitHub Packages.",
          "status": "todo"
        },
        {
          "id": "32.2",
          "title": "Verify package publication",
          "description": "Check that the package appears in the GitHub Packages section of the repository after the workflow runs.",
          "status": "todo"
        },
        {
          "id": "32.3",
          "title": "Test installation from GitHub Packages",
          "description": "Create a test environment and verify that the package can be installed using the instructions in the README.",
          "status": "todo"
        },
        {
          "id": "32.4",
          "title": "Coordinate with task #33 for installation instructions",
          "description": "Review task #33 and provide more detailed installation instructions if needed based on testing results.",
          "status": "todo"
        },
        {
          "id": "32.5",
          "title": "Create PyPI account and generate API token",
          "description": "Create a PyPI account if needed and generate a PyPI API token with upload scope for the package.",
          "status": "todo"
        },
        {
          "id": "32.6",
          "title": "Add PyPI token to GitHub repository secrets",
          "description": "Add the PyPI API token to GitHub repository secrets as PYPI_API_TOKEN for use in the workflow.",
          "status": "todo"
        },
        {
          "id": "32.7",
          "title": "Update subtasks 32.1-32.3 for PyPI instead of GitHub Packages",
          "description": "The original subtasks refer to GitHub Packages, but we're now using PyPI. When executing these tasks, verify publication to PyPI and test installation from PyPI instead.",
          "status": "todo"
        },
        {
          "id": 33.7,
          "title": "Test GitHub release workflow for PyPI",
          "description": "Create a GitHub release to test the publishing workflow and verify the package is correctly published to PyPI.",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": 34.7,
          "title": "Verify package publication on PyPI",
          "description": "Check that the package appears in the PyPI registry after the workflow runs successfully.",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": 35.7,
          "title": "Test installation from PyPI",
          "description": "Create a test environment and verify that the package can be installed from PyPI using the instructions in the README.",
          "details": "",
          "status": "pending",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": 36.7,
          "title": "Update package name in pyproject.toml",
          "description": "Update the package name in pyproject.toml from 'dannymexe-rag-package' to 'lawfirm-rag-package' for PyPI publishing.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": 37.7,
          "title": "Create GitHub Actions workflow for PyPI publishing",
          "description": "Create a GitHub Actions workflow file for publishing to PyPI using trusted publishing mechanism.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": 38.7,
          "title": "Update README with PyPI installation instructions",
          "description": "Update the README.md file with instructions for installing the package from PyPI.",
          "details": "",
          "status": "done",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": "32.8",
          "title": "Generate PyPI token with specific project scope",
          "description": "Generate a PyPI API token with the specific scope \"Upload to project: lawfirm-rag-package\" as required for the trusted publishing workflow.",
          "status": "todo",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": "32.9",
          "title": "Create GitHub release to trigger PyPI publication",
          "description": "Create a GitHub release with an appropriate version tag to trigger the PyPI publishing workflow.",
          "status": "todo",
          "dependencies": [],
          "parentTaskId": 32
        },
        {
          "id": "32.10",
          "title": "Verify trusted publishing configuration",
          "description": "Ensure the GitHub Actions workflow is correctly configured for PyPI's trusted publishing mechanism, which eliminates the need for API tokens to be passed directly in the workflow.",
          "status": "todo",
          "dependencies": [],
          "parentTaskId": 32
        }
      ]
    },
    {
      "id": 33,
      "title": "Update README.md with Private Repository Installation Instructions",
      "description": "Update the project's README.md with comprehensive installation instructions for the private GitHub repository, including collaborator access, token setup, and installing from GitHub Packages registry.",
      "details": "1. Update the README.md with the following sections:\n\n### Installation from Private GitHub Repository\n\n#### For Collaborators\n1. Add a section explaining how to request access to the repository:\n   ```markdown\n   ## Installation\n   \n   ### For Collaborators\n   \n   1. Request access to the repository by contacting the repository administrator\n   2. Once added as a collaborator, clone the repository:\n      ```bash\n      git clone https://github.com/organization/lawfirm-rag-package.git\n      cd lawfirm-rag-package\n      pip install -e .\n      ```\n   ```\n\n#### For Installing via GitHub Packages\n1. Add detailed instructions for creating a Personal Access Token (PAT):\n   ```markdown\n   ### Installing from GitHub Packages\n   \n   To install this package directly from GitHub Packages, you'll need to:\n   \n   1. Create a GitHub Personal Access Token (PAT):\n      - Go to GitHub → Settings → Developer settings → Personal access tokens\n      - Click \"Generate new token\"\n      - Select the `read:packages` scope\n      - Copy the generated token\n   \n   2. Configure pip to use GitHub Packages with authentication:\n      ```bash\n      # Create or edit ~/.pip/pip.conf (Linux/Mac) or %APPDATA%\\pip\\pip.ini (Windows)\n      [global]\n      index-url = https://username:TOKEN@maven.pkg.github.com/organization/lawfirm-rag-package/\n      ```\n      \n   3. Install the package:\n      ```bash\n      pip install lawfirm-rag-package\n      ```\n   ```\n\n#### For CI/CD Environments\n1. Add instructions for using GitHub Actions secrets:\n   ```markdown\n   ### For CI/CD Environments\n   \n   When installing in CI/CD pipelines:\n   \n   ```yaml\n   # Example GitHub Actions workflow step\n   - name: Install from GitHub Packages\n     run: |\n       pip install lawfirm-rag-package\n     env:\n       PIP_EXTRA_INDEX_URL: https://$${{ secrets.GITHUB_TOKEN }}@maven.pkg.github.com/organization/lawfirm-rag-package/\n   ```\n   ```\n\n2. Include troubleshooting section:\n   ```markdown\n   ### Troubleshooting\n   \n   - **Authentication Errors**: Ensure your token has the correct permissions\n   - **Package Not Found**: Verify you're using the correct repository URL\n   - **Version Issues**: Specify exact versions with `pip install lawfirm-rag-package==x.y.z`\n   ```\n\n3. Update any existing installation instructions to reflect the private nature of the package.\n\n4. Ensure the README includes a brief explanation of why the package is private and the benefits of using GitHub Packages for distribution.\n\n5. Add a section about versioning and releases that explains how to find and install specific versions from the GitHub Packages registry.",
      "testStrategy": "1. Verify README.md content:\n   - Ensure all sections (collaborator access, token setup, GitHub Packages installation) are present and accurate\n   - Check that code examples are properly formatted and syntactically correct\n   - Verify URLs and paths are correct for the organization's repository structure\n\n2. Test the installation instructions:\n   - Create a test GitHub account with no prior access to the repository\n   - Follow the README instructions to request access, create a token, and install the package\n   - Document any points of confusion or steps that need clarification\n\n3. Validate GitHub Packages installation:\n   - Create a fresh virtual environment\n   - Configure pip according to the instructions\n   - Attempt to install the package using the provided commands\n   - Verify the package installs correctly and can be imported\n\n4. Test CI/CD instructions:\n   - Create a simple test workflow in a separate repository\n   - Configure the workflow according to the README instructions\n   - Verify the package installs correctly in the CI environment\n\n5. Peer review:\n   - Have a team member unfamiliar with the project follow the instructions\n   - Collect feedback on clarity and completeness\n   - Make adjustments based on feedback\n\n6. Accessibility check:\n   - Ensure the README follows accessibility best practices\n   - Check that code blocks are properly formatted for screen readers\n   - Verify color contrast for any custom formatting",
      "status": "pending",
      "dependencies": [
        32
      ],
      "priority": "medium",
      "subtasks": []
    }
  ]
}
# Core dependencies
fastapi>=0.68.0
uvicorn>=0.15.0
requests>=2.25.0
pydantic>=1.8.0

# Document processing
PyPDF2>=3.0.0
python-docx>=0.8.11
python-multipart>=0.0.5

# CLI and UI
rich>=10.0.0
click>=8.0.0
Jinja2>=3.1.0

# Configuration and utilities
PyYAML>=5.4.0
python-dotenv>=1.0.0

# Optional dependencies:
# Install llama-cpp-python only if you want the GGUF backend:
# pip install llama-cpp-python>=0.2.0

# Development dependencies (install with: pip install -r requirements-dev.txt)
# pytest>=7.0.0
# pytest-asyncio>=0.21.0
# black>=23.0.0
# flake8>=6.0.0
# mypy>=1.0.0

# Optional dependencies for enhanced functionality
# psutil>=5.9.0  # For memory monitoring in model manager

# Document processing - enhanced
pdfplumber==0.9.0    # Better PDF text extraction - pinned for stability
PyMuPDF==1.23.8      # Alternative PDF processor (fitz) - pinned for stability

# Vector database and embeddings - WORKING VERSIONS
chromadb==0.4.15     # Local vector database - pinned for stability
numpy==1.24.3        # Required for embeddings - pinned for compatibility
sentence-transformers==4.1.0  # Latest stable version - tested working
torch==2.1.0+cpu     # CPU-optimized PyTorch - tested working

# Note: Install PyTorch with: pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu
# Note: Environment variables that may help: PYTORCH_DISABLE_PLATFORM_CHECK=1, OMP_NUM_THREADS=1

# AI/ML backends
ollama==0.1.9        # Ollama Python client - pinned for stability

# Additional ML dependencies for stability
transformers==4.35.2  # Transformers library - pinned for compatibility with sentence-transformers
tokenizers==0.15.0    # Tokenizers library - pinned for compatibility
huggingface-hub==0.19.4  # HuggingFace Hub - pinned for compatibility

# Optional: Additional text processing
# textstat>=0.7.3    # Text statistics
# spacy>=3.4.0       # Advanced NLP (optional) 